{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af201dd",
   "metadata": {},
   "source": [
    "# Prop 47 (CA) — State-level Synthetic Control (2010–2024)\n",
    "\n",
    "This notebook is a **clean replication** of the project:\n",
    "- Builds / loads a **state-month covered-population panel**\n",
    "- Runs **Synthetic Control** for CA with **in-space placebos** and **RMSPE filtering**\n",
    "- Fits weights using **pre-COVID window** (through 2019-12) and evaluates:\n",
    "  - **Post1:** 2014-11..2019-12 (or spec-defined)\n",
    "  - **COVID:** 2020-03..2021-12 (descriptive only)\n",
    "  - **Post2:** 2022-01..2024-12 (descriptive only)\n",
    "\n",
    "> Recommended workflow: keep `data/processed/state_month_covered.parquet` in the repo and set `REBUILD_PANEL=False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0) Setup\n",
    "# ============================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb99056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1) Config\n",
    "# ============================================================\n",
    "REPO_ROOT = Path(\".\")\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"   # optional: only used if REBUILD_PANEL=True\n",
    "PROCESSED_PATH = DATA_DIR / \"processed\" / \"state_month_covered.parquet\"\n",
    "\n",
    "OUT_DIR = REPO_ROOT / \"outputs\"\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "TAB_DIR = OUT_DIR / \"tables\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Toggle: rebuild processed panel from raw yearly parquet files\n",
    "REBUILD_PANEL = False\n",
    "\n",
    "# Expected raw pattern if rebuild:\n",
    "# data/raw/offenses_known_monthly_{year}.parquet\n",
    "RAW_FILE_PATTERN = \"offenses_known_monthly_{year}.parquet\"\n",
    "YEARS = range(2010, 2025)\n",
    "\n",
    "# Columns (raw parquet)\n",
    "RAW_COLUMNS = [\n",
    "    \"state_abb\", \"ori\", \"year\", \"month\", \"number_of_months_reported\",\n",
    "    \"population\", \"actual_theft_total\", \"actual_index_violent\"\n",
    "]\n",
    "\n",
    "# State code column names (processed)\n",
    "STATE_COL = \"state_abb\"\n",
    "DATE_COL = \"date\"\n",
    "\n",
    "# Outcomes (processed)\n",
    "OUTCOME_THEFT = \"theft_per_100k_coveredpop\"\n",
    "OUTCOME_VIOL  = \"violent_per_100k_coveredpop\"\n",
    "COVERAGE_COL  = \"coverage_rate\"\n",
    "\n",
    "# Treated\n",
    "TREATED = \"CA\"\n",
    "\n",
    "# Donor exclusions (DQ + non-states / territories)\n",
    "DQ_EXCLUDED = set([\"AR\",\"HI\",\"IN\",\"MI\",\"MS\",\"MT\",\"NE\",\"NH\",\"NY\",\"OH\",\"PA\",\"SD\",\"UT\",\"WV\",\"OR\",\"CZ\",\"PR\",\"GU\"])\n",
    "\n",
    "# Time windows\n",
    "DATE_MIN = pd.Timestamp(\"2010-01-01\")\n",
    "FIT_END  = pd.Timestamp(\"2019-12-01\")   # fit weights only through 2019\n",
    "FULL_END = pd.Timestamp(\"2024-12-01\")   # evaluate through 2024\n",
    "\n",
    "# COVID segmentation (descriptive)\n",
    "COVID_START = pd.Timestamp(\"2020-03-01\")\n",
    "COVID_END   = pd.Timestamp(\"2021-12-01\")\n",
    "POST2_START = pd.Timestamp(\"2022-01-01\")\n",
    "\n",
    "# Specs: (spec_id, outcome_col, t0, pre_start)\n",
    "SPECS = [\n",
    "    (\"S0\", OUTCOME_THEFT, pd.Timestamp(\"2014-11-01\"), pd.Timestamp(\"2010-01-01\")),\n",
    "    (\"S1\", OUTCOME_THEFT, pd.Timestamp(\"2015-01-01\"), pd.Timestamp(\"2010-01-01\")),\n",
    "    (\"S2\", OUTCOME_THEFT, pd.Timestamp(\"2014-11-01\"), pd.Timestamp(\"2012-01-01\")),\n",
    "    (\"N0\", OUTCOME_VIOL,  pd.Timestamp(\"2014-11-01\"), pd.Timestamp(\"2010-01-01\")),\n",
    "]\n",
    "\n",
    "# Placebo filter multipliers (tighter = stricter)\n",
    "PRE_RMSPE_MULTS = [2.0, 1.5]\n",
    "\n",
    "MIN_DONORS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) Helpers (panel build + validation)\n",
    "# ============================================================\n",
    "MISSING_TOKENS = {\"\", \"none\", \"nan\", \"null\"}\n",
    "\n",
    "def mstart(x) -> pd.Timestamp:\n",
    "    return pd.to_datetime(x).to_period(\"M\").to_timestamp()\n",
    "\n",
    "def normalize_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL]).dt.to_period(\"M\").dt.to_timestamp()\n",
    "    return df\n",
    "\n",
    "def require_cols(df: pd.DataFrame, cols: List[str]) -> None:\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "def flag_missing(group: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Mark n_missing months within an ORI-year as missing using number_of_months_reported.\"\"\"\n",
    "    n_missing = int(12 - group[\"number_of_months_reported\"].iloc[0])\n",
    "    n_missing = max(0, min(n_missing, len(group)))\n",
    "    group = group.sort_values([\"actual_theft_total\", \"actual_index_violent\"], ascending=True).copy()\n",
    "    group[\"month_missing\"] = False\n",
    "    if n_missing > 0:\n",
    "        group.iloc[:n_missing, group.columns.get_loc(\"month_missing\")] = True\n",
    "    return group\n",
    "\n",
    "def build_state_month_covered_from_raw(raw_dir: Path, years=range(2010, 2025)) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for year in years:\n",
    "        fp = raw_dir / RAW_FILE_PATTERN.format(year=year)\n",
    "        if not fp.exists():\n",
    "            raise FileNotFoundError(f\"Missing raw file: {fp}\")\n",
    "        df = pd.read_parquet(fp, columns=RAW_COLUMNS)\n",
    "\n",
    "        # Drop bad state codes / non-states / nulls\n",
    "        s = df[\"state_abb\"].astype(\"string\").str.strip()\n",
    "        s_lower = s.str.lower()\n",
    "        bad = s.isna() | s_lower.isin(MISSING_TOKENS) | s.isin(DQ_EXCLUDED)\n",
    "        df = df.loc[~bad].copy()\n",
    "\n",
    "        # Flag missing months within ORI-year\n",
    "        df = df.groupby([\"ori\", \"year\"], group_keys=False).apply(flag_missing)\n",
    "        frames.append(df)\n",
    "\n",
    "    raw = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "    # Date\n",
    "    # (Raw files store month as full month name; if numeric, this still works via fallback)\n",
    "    dt = pd.to_datetime(\n",
    "        raw[\"year\"].astype(int).astype(str) + \" \" + raw[\"month\"].astype(str),\n",
    "        format=\"%Y %B\",\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "    if dt.isna().any():\n",
    "        # fallback: try month number\n",
    "        dt2 = pd.to_datetime(\n",
    "            raw[\"year\"].astype(int).astype(str) + \"-\" + raw[\"month\"].astype(str).str.zfill(2) + \"-01\",\n",
    "            errors=\"coerce\",\n",
    "        )\n",
    "        dt = dt.fillna(dt2)\n",
    "    raw[\"date\"] = dt.dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "    # Covered population\n",
    "    raw[\"pop_covered\"] = raw[\"population\"] * (~raw[\"month_missing\"]).astype(int)\n",
    "\n",
    "    # Aggregate to state-month\n",
    "    sm = (\n",
    "        raw.groupby([\"state_abb\", \"date\"], as_index=False)\n",
    "           .agg(\n",
    "               total_pop=(\"population\", \"sum\"),\n",
    "               covered_pop=(\"pop_covered\", \"sum\"),\n",
    "               theft=(\"actual_theft_total\", \"sum\"),\n",
    "               violent=(\"actual_index_violent\", \"sum\"),\n",
    "           )\n",
    "    )\n",
    "    sm[\"coverage_rate\"] = sm[\"covered_pop\"] / sm[\"total_pop\"]\n",
    "\n",
    "    # Rates (avoid Inf)\n",
    "    sm[\"theft_per_100k_coveredpop\"] = np.where(\n",
    "        sm[\"covered_pop\"] > 0, (sm[\"theft\"] / sm[\"covered_pop\"]) * 100000.0, np.nan\n",
    "    )\n",
    "    sm[\"violent_per_100k_coveredpop\"] = np.where(\n",
    "        sm[\"covered_pop\"] > 0, (sm[\"violent\"] / sm[\"covered_pop\"]) * 100000.0, np.nan\n",
    "    )\n",
    "    return sm\n",
    "\n",
    "def clean_nonfinite(series: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    s = s.replace([np.inf, -np.inf], np.nan)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ed7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) Load (or build) processed panel\n",
    "# ============================================================\n",
    "if REBUILD_PANEL:\n",
    "    print(\"[Build] Rebuilding processed panel from raw ...\")\n",
    "    df_sm = build_state_month_covered_from_raw(RAW_DIR, years=YEARS)\n",
    "    (DATA_DIR / \"processed\").mkdir(parents=True, exist_ok=True)\n",
    "    df_sm.to_parquet(PROCESSED_PATH, index=False)\n",
    "    print(f\"[Build] Wrote {PROCESSED_PATH}  rows={len(df_sm):,}\")\n",
    "else:\n",
    "    print(\"[Load] Loading processed panel ...\")\n",
    "    if not PROCESSED_PATH.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Processed panel not found at {PROCESSED_PATH}. \"\n",
    "            \"Either add it to the repo, or set REBUILD_PANEL=True and point RAW_DIR to your raw files.\"\n",
    "        )\n",
    "    df_sm = pd.read_parquet(PROCESSED_PATH)\n",
    "\n",
    "df_sm = normalize_df(df_sm)\n",
    "\n",
    "# Basic schema checks\n",
    "require_cols(df_sm, [STATE_COL, DATE_COL, OUTCOME_THEFT, OUTCOME_VIOL, COVERAGE_COL])\n",
    "\n",
    "# Drop DQ excluded states (safety)\n",
    "df_sm = df_sm[~df_sm[STATE_COL].isin(DQ_EXCLUDED)].copy()\n",
    "\n",
    "# Clean non-finite outcomes (should be rare at state level)\n",
    "df_sm[OUTCOME_THEFT] = clean_nonfinite(df_sm[OUTCOME_THEFT])\n",
    "df_sm[OUTCOME_VIOL]  = clean_nonfinite(df_sm[OUTCOME_VIOL])\n",
    "df_sm[COVERAGE_COL]  = clean_nonfinite(df_sm[COVERAGE_COL])\n",
    "\n",
    "print(\"States:\", df_sm[STATE_COL].nunique(), \"Date range:\", df_sm[DATE_COL].min(), \"→\", df_sm[DATE_COL].max())\n",
    "df_sm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883cb59",
   "metadata": {},
   "source": [
    "## Donor pool diagnostics (quick)\n",
    "This is a lightweight sanity check. Your more detailed QC lives in `docs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4) Quick donor pool QC (optional but recommended)\n",
    "# ============================================================\n",
    "pre_period = (df_sm[DATE_COL] >= pd.Timestamp(\"2010-01-01\")) & (df_sm[DATE_COL] < pd.Timestamp(\"2014-11-01\"))\n",
    "\n",
    "coverage_by_state = (\n",
    "    df_sm.loc[pre_period]\n",
    "        .groupby(STATE_COL)[COVERAGE_COL]\n",
    "        .agg([\"mean\", \"std\", \"min\", \"max\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    ")\n",
    "\n",
    "coverage_by_state.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep donors with mean pre coverage >= 0.95 (baseline rule)\n",
    "eligible_states = coverage_by_state[coverage_by_state[\"mean\"] >= 0.95].index.tolist()\n",
    "eligible_states = sorted([s for s in eligible_states if s != TREATED])\n",
    "print(\"Eligible donors (>=0.95 mean pre coverage):\", len(eligible_states))\n",
    "print(\"Example donors:\", eligible_states[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08b211e",
   "metadata": {},
   "source": [
    "## SCM implementation\n",
    "Weights are fit on `[DATE_MIN..FIT_END]` and projected through `FULL_END`.\n",
    "\n",
    "Inference uses **in-space placebos** filtered by `pre_rmspe_placebo <= m × pre_rmspe_treated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5) SCM core (stable solver + fit + placebos)\n",
    "# ============================================================\n",
    "def build_panel(df: pd.DataFrame, states: List[str], outcome: str,\n",
    "                date_min: pd.Timestamp, date_max: pd.Timestamp) -> pd.DataFrame:\n",
    "    sub = df[df[STATE_COL].isin(states)].copy()\n",
    "    Y = (sub.pivot_table(index=DATE_COL, columns=STATE_COL, values=outcome, aggfunc=\"mean\")\n",
    "           .sort_index())\n",
    "    return Y.loc[mstart(date_min):mstart(date_max)]\n",
    "\n",
    "def solve_scm_weights(y_pre: np.ndarray, X_pre: np.ndarray) -> Tuple[np.ndarray, str]:\n",
    "    y_pre = np.asarray(y_pre).reshape(-1)\n",
    "    X_pre = np.asarray(X_pre)\n",
    "\n",
    "    if X_pre.ndim != 2:\n",
    "        raise ValueError(f\"X_pre must be 2D, got {X_pre.shape}\")\n",
    "    T0, J = X_pre.shape\n",
    "    if T0 == 0 or J == 0:\n",
    "        raise ValueError(f\"Empty pre matrices: T0={T0}, J={J}\")\n",
    "\n",
    "    if not np.all(np.isfinite(y_pre)) or not np.all(np.isfinite(X_pre)):\n",
    "        raise ValueError(\"Non-finite values in pre matrices (NaN/Inf).\")\n",
    "\n",
    "    # scale for numerical stability\n",
    "    scale = float(np.std(y_pre))\n",
    "    if not np.isfinite(scale) or scale <= 0:\n",
    "        scale = 1.0\n",
    "    y = y_pre / scale\n",
    "    X = X_pre / scale\n",
    "\n",
    "    w = cp.Variable(J)\n",
    "    prob = cp.Problem(cp.Minimize(cp.sum_squares(y - X @ w)), [w >= 0, cp.sum(w) == 1])\n",
    "\n",
    "    status = \"unknown\"\n",
    "    try:\n",
    "        prob.solve(solver=cp.OSQP, verbose=False, max_iter=200000, eps_abs=1e-8, eps_rel=1e-8)\n",
    "        status = prob.status\n",
    "    except Exception:\n",
    "        prob.solve(solver=cp.SCS, verbose=False, max_iters=200000, eps=1e-6)\n",
    "        status = prob.status\n",
    "\n",
    "    if w.value is None:\n",
    "        raise ValueError(f\"SCM optimization failed: status={status}\")\n",
    "\n",
    "    wv = np.array(w.value).reshape(-1)\n",
    "    wv[wv < 0] = 0.0\n",
    "    sm = float(wv.sum())\n",
    "    if sm <= 0:\n",
    "        raise ValueError(\"Degenerate weights.\")\n",
    "    return wv / sm, status\n",
    "\n",
    "def segment_metrics(dates: pd.DatetimeIndex, gap: np.ndarray,\n",
    "                    start: pd.Timestamp, end: pd.Timestamp) -> Tuple[float, float, int]:\n",
    "    mask = (dates >= start) & (dates <= end)\n",
    "    g = gap[mask]\n",
    "    g = g[np.isfinite(g)]\n",
    "    if g.size == 0:\n",
    "        return np.nan, np.nan, 0\n",
    "    rmspe = float(np.sqrt(np.mean(g**2)))\n",
    "    avg = float(np.mean(g))\n",
    "    return rmspe, avg, int(g.size)\n",
    "\n",
    "def fit_one(df: pd.DataFrame, treated: str, outcome: str, donors: List[str],\n",
    "            pre_start, t0, date_min, fit_end, full_end,\n",
    "            min_donors: int = 5) -> Dict[str, Any]:\n",
    "\n",
    "    t0 = mstart(t0); pre_start=mstart(pre_start)\n",
    "    date_min=mstart(date_min); fit_end=mstart(fit_end); full_end=mstart(full_end)\n",
    "\n",
    "    # Fit window (pre-COVID)\n",
    "    Y_fit = build_panel(df, [treated] + donors, outcome, date_min, fit_end)\n",
    "    if treated not in Y_fit.columns:\n",
    "        raise ValueError(f\"Treated '{treated}' missing after pivot.\")\n",
    "\n",
    "    pre_mask = (Y_fit.index >= pre_start) & (Y_fit.index < t0)\n",
    "    if pre_mask.sum() == 0:\n",
    "        raise ValueError(\"No pre rows in fit window.\")\n",
    "\n",
    "    # treated must be finite in pre\n",
    "    if not np.all(np.isfinite(Y_fit.loc[pre_mask, treated].to_numpy())):\n",
    "        raise ValueError(\"Treated has non-finite values in pre.\")\n",
    "\n",
    "    # donors complete in pre and fit window\n",
    "    donors_complete = []\n",
    "    for d in donors:\n",
    "        if d not in Y_fit.columns:\n",
    "            continue\n",
    "        col = Y_fit[d].to_numpy()\n",
    "        if np.all(np.isfinite(Y_fit.loc[pre_mask, d].to_numpy())) and np.all(np.isfinite(col)):\n",
    "            donors_complete.append(d)\n",
    "\n",
    "    if len(donors_complete) < min_donors:\n",
    "        raise ValueError(f\"Too few complete donors: {len(donors_complete)} (<{min_donors})\")\n",
    "\n",
    "    y_pre = Y_fit.loc[pre_mask, treated].to_numpy()\n",
    "    X_pre = Y_fit.loc[pre_mask, donors_complete].to_numpy()\n",
    "\n",
    "    w, status = solve_scm_weights(y_pre, X_pre)\n",
    "    w_ser = pd.Series(w, index=donors_complete).sort_values(ascending=False)\n",
    "\n",
    "    active = w_ser[w_ser > 1e-6].index.tolist()\n",
    "    if len(active) == 0:\n",
    "        active = donors_complete\n",
    "\n",
    "    # Full window evaluation (drop rows with any missing among treated+active)\n",
    "    Y_full = build_panel(df, [treated] + active, outcome, date_min, full_end).dropna(axis=0, how=\"any\")\n",
    "    dates = Y_full.index\n",
    "\n",
    "    y = Y_full[treated].to_numpy()\n",
    "    X = Y_full[active].to_numpy()\n",
    "\n",
    "    w_active = w_ser.reindex(active).fillna(0.0).to_numpy()\n",
    "    w_active = w_active / (w_active.sum() + 1e-12)\n",
    "\n",
    "    y_synth = X @ w_active\n",
    "    gap = y - y_synth\n",
    "\n",
    "    # Segment windows\n",
    "    pre_end = (t0 - pd.offsets.MonthBegin(1))\n",
    "    pre_rmspe, _, n_pre = segment_metrics(dates, gap, pre_start, pre_end)\n",
    "    post1_rmspe, avg_post1, n_post1 = segment_metrics(dates, gap, t0, fit_end)\n",
    "    covid_rmspe, avg_covid, n_covid = segment_metrics(dates, gap, COVID_START, COVID_END)\n",
    "    post2_rmspe, avg_post2, n_post2 = segment_metrics(dates, gap, POST2_START, full_end)\n",
    "\n",
    "    ratio_post1 = post1_rmspe / (pre_rmspe + 1e-12) if np.isfinite(post1_rmspe) and np.isfinite(pre_rmspe) else np.nan\n",
    "    ratio_post2 = post2_rmspe / (pre_rmspe + 1e-12) if np.isfinite(post2_rmspe) and np.isfinite(pre_rmspe) else np.nan\n",
    "\n",
    "    return {\n",
    "        \"treated\": treated,\n",
    "        \"outcome\": outcome,\n",
    "        \"t0\": t0,\n",
    "        \"pre_start\": pre_start,\n",
    "        \"date_min\": date_min,\n",
    "        \"fit_end\": fit_end,\n",
    "        \"full_end\": full_end,\n",
    "\n",
    "        \"donors_requested\": donors,\n",
    "        \"donors_complete_pre\": donors_complete,\n",
    "        \"donors_active\": active,\n",
    "\n",
    "        \"weights\": pd.Series(w_active, index=active).sort_values(ascending=False),\n",
    "        \"solver_status\": status,\n",
    "\n",
    "        \"dates\": dates,\n",
    "        \"y\": y,\n",
    "        \"y_synth\": y_synth,\n",
    "        \"gap\": gap,\n",
    "\n",
    "        \"pre_rmspe\": float(pre_rmspe),\n",
    "        \"post1_rmspe\": float(post1_rmspe),\n",
    "        \"post2_rmspe\": float(post2_rmspe),\n",
    "        \"ratio_post1\": float(ratio_post1),\n",
    "        \"ratio_post2\": float(ratio_post2),\n",
    "\n",
    "        \"avg_gap_post1\": float(avg_post1) if np.isfinite(avg_post1) else np.nan,\n",
    "        \"avg_gap_covid\": float(avg_covid) if np.isfinite(avg_covid) else np.nan,\n",
    "        \"avg_gap_post2\": float(avg_post2) if np.isfinite(avg_post2) else np.nan,\n",
    "\n",
    "        \"n_pre\": int(n_pre),\n",
    "        \"n_post1\": int(n_post1),\n",
    "        \"n_covid\": int(n_covid),\n",
    "        \"n_post2\": int(n_post2),\n",
    "    }\n",
    "\n",
    "def placebo_loop(df: pd.DataFrame, treated_res: Dict[str, Any], donors_base: List[str],\n",
    "                 pre_rmspe_mult: float = 2.0, min_donors: int = 5, verbose: bool=False) -> Tuple[pd.DataFrame, pd.DataFrame, float, float]:\n",
    "    rows = []\n",
    "    for s in donors_base:\n",
    "        donors_s = [d for d in donors_base if d != s]\n",
    "        try:\n",
    "            r = fit_one(\n",
    "                df, treated=s, outcome=treated_res[\"outcome\"], donors=donors_s,\n",
    "                pre_start=treated_res[\"pre_start\"], t0=treated_res[\"t0\"],\n",
    "                date_min=treated_res[\"date_min\"], fit_end=treated_res[\"fit_end\"], full_end=treated_res[\"full_end\"],\n",
    "                min_donors=min_donors,\n",
    "            )\n",
    "            rows.append({\"state\": s, \"pre_rmspe\": r[\"pre_rmspe\"], \"ratio_post1\": r[\"ratio_post1\"], \"ratio_post2\": r[\"ratio_post2\"]})\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(\"Skipping\", s, \":\", e)\n",
    "            continue\n",
    "\n",
    "    all_df = pd.DataFrame(rows).dropna()\n",
    "    thr = float(pre_rmspe_mult) * float(treated_res[\"pre_rmspe\"])\n",
    "    filt = all_df[all_df[\"pre_rmspe\"] <= thr].copy()\n",
    "\n",
    "    def pval(col: str, treated_val: float) -> float:\n",
    "        vals = filt[col].to_numpy()\n",
    "        vals = vals[np.isfinite(vals)]\n",
    "        if vals.size == 0 or not np.isfinite(treated_val):\n",
    "            return np.nan\n",
    "        return float((1 + np.sum(vals >= treated_val)) / (1 + vals.size))\n",
    "\n",
    "    p1 = pval(\"ratio_post1\", treated_res[\"ratio_post1\"])\n",
    "    p2 = pval(\"ratio_post2\", treated_res[\"ratio_post2\"])\n",
    "    return all_df, filt, p1, p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e86a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6) Plot helpers\n",
    "# ============================================================\n",
    "def plot_treated_vs_synth(res: Dict[str, Any], title: str, outpath: Path) -> None:\n",
    "    plt.figure()\n",
    "    plt.plot(res[\"dates\"], res[\"y\"], label=res[\"treated\"])\n",
    "    plt.plot(res[\"dates\"], res[\"y_synth\"], label=\"Synthetic\")\n",
    "    plt.axvline(res[\"t0\"], linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    outpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_gap(res: Dict[str, Any], title: str, outpath: Path) -> None:\n",
    "    plt.figure()\n",
    "    plt.plot(res[\"dates\"], res[\"gap\"])\n",
    "    plt.axhline(0, linewidth=1)\n",
    "    plt.axvline(res[\"t0\"], linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    outpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_placebo_hist(filt: pd.DataFrame, treated_val: float, col: str, title: str, outpath: Path) -> None:\n",
    "    vals = filt[col].to_numpy()\n",
    "    vals = vals[np.isfinite(vals)]\n",
    "    plt.figure()\n",
    "    plt.hist(vals, bins=20)\n",
    "    if np.isfinite(treated_val):\n",
    "        plt.axvline(treated_val, linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    outpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e9002",
   "metadata": {},
   "source": [
    "## Run all specs (state-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3062998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7) Run specs\n",
    "# ============================================================\n",
    "summary_rows = []\n",
    "\n",
    "for spec_id, outcome, t0, pre_start in SPECS:\n",
    "    print(\"Running\", spec_id, outcome, \"t0=\", t0.date(), \"pre_start=\", pre_start.date())\n",
    "\n",
    "    # donors: eligible by coverage rule (>=0.95 mean pre coverage)\n",
    "    donors = eligible_states.copy()\n",
    "\n",
    "    # Fit treated\n",
    "    tr = fit_one(\n",
    "        df_sm, treated=TREATED, outcome=outcome, donors=donors,\n",
    "        pre_start=pre_start, t0=t0,\n",
    "        date_min=DATE_MIN, fit_end=FIT_END, full_end=FULL_END,\n",
    "        min_donors=MIN_DONORS\n",
    "    )\n",
    "\n",
    "    # Save weights + plots\n",
    "    tr[\"weights\"].to_csv(TAB_DIR / f\"{spec_id}_weights.csv\", header=[\"weight\"])\n",
    "    plot_treated_vs_synth(tr, f\"{spec_id}: {TREATED} vs Synthetic ({outcome})\", FIG_DIR / f\"{spec_id}_treated_vs_synth.png\")\n",
    "    plot_gap(tr, f\"{spec_id}: Gap (Treated - Synth) ({outcome})\", FIG_DIR / f\"{spec_id}_gap.png\")\n",
    "\n",
    "    # Placebos for each multiplier\n",
    "    for m in PRE_RMSPE_MULTS:\n",
    "        pl_all, pl_filt, p1, p2 = placebo_loop(df_sm, tr, tr[\"donors_complete_pre\"], pre_rmspe_mult=m, min_donors=MIN_DONORS)\n",
    "        pl_all.to_csv(TAB_DIR / f\"{spec_id}_placebos_all_m{m}.csv\", index=False)\n",
    "        pl_filt.to_csv(TAB_DIR / f\"{spec_id}_placebos_filt_m{m}.csv\", index=False)\n",
    "\n",
    "        if len(pl_filt) > 0:\n",
    "            plot_placebo_hist(pl_filt, tr[\"ratio_post1\"], \"ratio_post1\",\n",
    "                              f\"{spec_id}: Placebo ratios post1 (m={m}) p={p1:.3f}\", FIG_DIR / f\"{spec_id}_hist_ratio_post1_m{m}.png\")\n",
    "            plot_placebo_hist(pl_filt, tr[\"ratio_post2\"], \"ratio_post2\",\n",
    "                              f\"{spec_id}: Placebo ratios post2 (m={m}) p={p2:.3f}\", FIG_DIR / f\"{spec_id}_hist_ratio_post2_m{m}.png\")\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"spec_id\": f\"{spec_id}_m{m}\",\n",
    "            \"outcome\": outcome,\n",
    "            \"t0\": str(tr[\"t0\"].date()),\n",
    "            \"pre_start\": str(tr[\"pre_start\"].date()),\n",
    "            \"date_min\": str(tr[\"date_min\"].date()),\n",
    "            \"fit_end\": str(tr[\"fit_end\"].date()),\n",
    "            \"full_end\": str(tr[\"full_end\"].date()),\n",
    "            \"n_donors_requested\": len(donors),\n",
    "            \"n_donors_complete_pre\": len(tr[\"donors_complete_pre\"]),\n",
    "            \"n_donors_active\": len(tr[\"donors_active\"]),\n",
    "            \"pre_rmspe\": tr[\"pre_rmspe\"],\n",
    "            \"post1_rmspe\": tr[\"post1_rmspe\"],\n",
    "            \"post2_rmspe\": tr[\"post2_rmspe\"],\n",
    "            \"ratio_post1\": tr[\"ratio_post1\"],\n",
    "            \"ratio_post2\": tr[\"ratio_post2\"],\n",
    "            \"avg_gap_post1\": tr[\"avg_gap_post1\"],\n",
    "            \"avg_gap_covid\": tr[\"avg_gap_covid\"],\n",
    "            \"avg_gap_post2\": tr[\"avg_gap_post2\"],\n",
    "            \"n_months_pre\": tr[\"n_pre\"],\n",
    "            \"n_months_post1\": tr[\"n_post1\"],\n",
    "            \"n_months_covid\": tr[\"n_covid\"],\n",
    "            \"n_months_post2\": tr[\"n_post2\"],\n",
    "            \"n_placebos\": len(pl_all),\n",
    "            \"n_placebos_filtered\": len(pl_filt),\n",
    "            \"pre_rmspe_mult\": float(m),\n",
    "            \"pval_ratio_post1\": p1,\n",
    "            \"pval_ratio_post2\": p2,\n",
    "            \"solver_status\": tr[\"solver_status\"],\n",
    "        })\n",
    "\n",
    "summary = pd.DataFrame(summary_rows).sort_values([\"spec_id\"]).reset_index(drop=True)\n",
    "summary.to_csv(TAB_DIR / \"all_specs_summary.csv\", index=False)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d313942",
   "metadata": {},
   "source": [
    "## Quick view: top donor weights (S0 theft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8) Inspect key artifact\n",
    "# ============================================================\n",
    "try:\n",
    "    w = pd.read_csv(TAB_DIR / \"S0_weights.csv\", index_col=0)[\"weight\"].sort_values(ascending=False)\n",
    "    w.head(15)\n",
    "except Exception as e:\n",
    "    print(\"No S0_weights.csv found yet:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d12c0",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- If you want to include county-level work later, do it as a *separate notebook* to avoid polluting the replication artifact.\n",
    "- If you extend the donor QC beyond coverage, add it in section 4 and keep it documented in `docs/data_qc_report.md`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
